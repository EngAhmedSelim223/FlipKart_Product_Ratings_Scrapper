{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import logging\n",
    "import threading \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we enter the name of the product we want to search \n",
    "search_product = input(\"please Enter the Product name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all pages links for all pages which contain that product\n",
    "product_pages = []\n",
    "for i in range(1,50):\n",
    "    try:\n",
    "        product_page_url = \"https://www.flipkart.com/search?q=\" + search_product + \"&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(i)\n",
    "        product_pages.append(product_page_url)\n",
    "    except Exception as e :\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pages_lst = []\n",
    "def product_pages_text_source(page_link):\n",
    "    text_pages_lst.append(requests.get(page_link).text)\n",
    "    return text_pages_lst\n",
    "\n",
    "thred1 = [threading.Thread(target=product_pages_text_source, args=(i,))  for i in product_pages]\n",
    "for t in thred1:\n",
    "    t.start()\n",
    "for t in thred1:\n",
    "    t.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_pages_lst = []\n",
    "def product_pages_html_source(text_source_link):\n",
    "    html_pages_lst.append(BeautifulSoup(text_source_link, \"html.parser\"))\n",
    "    return html_pages_lst\n",
    "\n",
    "thred2 = [threading.Thread(target=product_pages_html_source, args=(i,))  for i in text_pages_lst]\n",
    "for t in thred2:\n",
    "    t.start()\n",
    "for t in thred2:\n",
    "    t.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all info boxes for all products in all pages\n",
    "product_info_box_lst = []\n",
    "\n",
    "def get_product_info_box(html_page):\n",
    "    info_boxs = html_page.find_all(\"div\", {\"class\":\"_1AtVbE col-12-12\"})\n",
    "    del info_boxs[:2]\n",
    "    del info_boxs[len(info_boxs)-3:]\n",
    "    for box in info_boxs:\n",
    "        product_info_box_lst.append(box)\n",
    "    return product_info_box_lst\n",
    "\n",
    "\n",
    "thred3 = [threading.Thread(target=get_product_info_box, args=(i,))  for i in html_pages_lst]\n",
    "for t in thred3:\n",
    "    t.start()\n",
    "for t in thred3:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_info_box_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the links for all products in all product_info_box in all pages that contain that product\n",
    "products_links_lst = []\n",
    "\n",
    "def get_product_link(info_box):\n",
    "    \n",
    "    try:\n",
    "        product_link = \"https://www.flipkart.com\"+info_box.div.div.div.a['href']\n",
    "        products_links_lst.append(product_link)\n",
    "    except Exception as e :\n",
    "        pass\n",
    "    return products_links_lst\n",
    "\n",
    "\n",
    "thred4 = [threading.Thread(target=get_product_link, args=(i,))  for i in product_info_box_lst]\n",
    "for t in thred4:\n",
    "    t.start()\n",
    "for t in thred4:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_links_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all review boxes in all pages for each product link\n",
    "products_review_lst = []\n",
    "def get_review_boxes(product_link):\n",
    "    review_text = requests.get(product_link).text\n",
    "    review_html = BeautifulSoup(review_text, \"html.parser\")\n",
    "    review_boxs = review_html.find_all(\"div\", {\"class\": \"_16PBlm\"})\n",
    "\n",
    "    for box in review_boxs:\n",
    "        products_review_lst.append(box)\n",
    "    return products_review_lst\n",
    "\n",
    "thred5 = [threading.Thread(target=get_review_boxes, args=(i,))  for i in products_links_lst]\n",
    "for t in thred5:\n",
    "    t.start()\n",
    "for t in thred5:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6949"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_review_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ratings and the reviews owners form all review boxes\n",
    "product_ratings = []\n",
    "product_reviews_writers = []\n",
    "\n",
    "def get_ratings_writers(product_review):\n",
    "    try:\n",
    "\n",
    "        rating = product_review.div.div.div.find_all(\"div\", {\"class\": \"_3LWZlK _1BLPMq\"})[0].text\n",
    "        writer = product_review.div.div.find_all(\"p\", {\"class\": \"_2sc7ZR _2V5EHH\"})[0].text\n",
    "        product_ratings.append(rating)\n",
    "        product_reviews_writers.append(writer)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    return product_ratings, product_reviews_writers\n",
    "\n",
    "thred6 = [threading.Thread(target=get_ratings_writers, args=(i,))  for i in products_review_lst]\n",
    "for t in thred6:\n",
    "    t.start()\n",
    "for t in thred6:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapped_data = {}\n",
    "for item in range(len(product_ratings)):\n",
    "    scrapped_data[product_reviews_writers[item]] = product_ratings[item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1735"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scrapped_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
